{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4mZmWxyUd0T",
        "outputId": "7c00b7f0-b6d3-4f05-d814-d4039c203197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'flappy-bird-gym'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/24)\u001b[K\rremote: Counting objects:   8% (2/24)\u001b[K\rremote: Counting objects:  12% (3/24)\u001b[K\rremote: Counting objects:  16% (4/24)\u001b[K\rremote: Counting objects:  20% (5/24)\u001b[K\rremote: Counting objects:  25% (6/24)\u001b[K\rremote: Counting objects:  29% (7/24)\u001b[K\rremote: Counting objects:  33% (8/24)\u001b[K\rremote: Counting objects:  37% (9/24)\u001b[K\rremote: Counting objects:  41% (10/24)\u001b[K\rremote: Counting objects:  45% (11/24)\u001b[K\rremote: Counting objects:  50% (12/24)\u001b[K\rremote: Counting objects:  54% (13/24)\u001b[K\rremote: Counting objects:  58% (14/24)\u001b[K\rremote: Counting objects:  62% (15/24)\u001b[K\rremote: Counting objects:  66% (16/24)\u001b[K\rremote: Counting objects:  70% (17/24)\u001b[K\rremote: Counting objects:  75% (18/24)\u001b[K\rremote: Counting objects:  79% (19/24)\u001b[K\rremote: Counting objects:  83% (20/24)\u001b[K\rremote: Counting objects:  87% (21/24)\u001b[K\rremote: Counting objects:  91% (22/24)\u001b[K\rremote: Counting objects:  95% (23/24)\u001b[K\rremote: Counting objects: 100% (24/24)\u001b[K\rremote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 159 (delta 20), reused 18 (delta 18), pack-reused 135\u001b[K\n",
            "Receiving objects: 100% (159/159), 65.05 MiB | 48.84 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Talendar/flappy-bird-gym.git\n",
        "# Passer le boolean audio_on: bool = False dans \n",
        "# flappy-bird-gym/flappy_bird_gym/envs/renderer.py /"
      ],
      "id": "M4mZmWxyUd0T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awr4neo8Urjg",
        "outputId": "efdbcbd8-7b8f-44d6-d7a8-32056b615ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 98.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pygame"
      ],
      "id": "awr4neo8Urjg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blmGmNnSU3Qs"
      },
      "outputs": [],
      "source": [
        "import os"
      ],
      "id": "blmGmNnSU3Qs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "put_-KC9Uzyd",
        "outputId": "f30fe062-b712-499b-c8c9-9c52ae08385c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/flappy-bird-gym\n"
          ]
        }
      ],
      "source": [
        "print(os.getcwd())\n",
        "os.chdir(os.getcwd() + '/flappy-bird-gym/')\n",
        "print(os.getcwd())"
      ],
      "id": "put_-KC9Uzyd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIevNqdGVRBK"
      },
      "outputs": [],
      "source": [
        "from flappy_bird_gym.envs.flappy_bird_env_rgb import FlappyBirdEnvRGB"
      ],
      "id": "CIevNqdGVRBK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVXVNjtfVN3I"
      },
      "outputs": [],
      "source": [
        "env = FlappyBirdEnvRGB()"
      ],
      "id": "tVXVNjtfVN3I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_udxuXjVW69",
        "outputId": "6d13beaf-84e7-4c07-bb56-07e23fd9765f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(288, 512, 3)\n"
          ]
        }
      ],
      "source": [
        "state = env.reset()\n",
        "print(state.shape)"
      ],
      "id": "N_udxuXjVW69"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64d04c3e-7839-4503-b2e5-9762318894fc"
      },
      "source": [
        "# Flappy Bird RGB version for D3QN"
      ],
      "id": "64d04c3e-7839-4503-b2e5-9762318894fc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5572f5e2-18de-4e2c-b295-72d5ccfed086"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import time\n",
        "import cv2\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "id": "5572f5e2-18de-4e2c-b295-72d5ccfed086"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaca3fb5-8a53-4db8-8b94-c0808335567d"
      },
      "outputs": [],
      "source": [
        "env = FlappyBirdEnvRGB()"
      ],
      "id": "eaca3fb5-8a53-4db8-8b94-c0808335567d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35396e31-ea8b-4054-b700-9ac3075ef14f"
      },
      "source": [
        "## Image pre processing"
      ],
      "id": "35396e31-ea8b-4054-b700-9ac3075ef14f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e97aaab-d2d0-4bb0-861d-e7f8e3eefdc6",
        "outputId": "6c2c4627-f5d0-42be-f28e-bf068f518da5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(288, 512, 3)\n"
          ]
        }
      ],
      "source": [
        "state = env.reset()\n",
        "print(state.shape)"
      ],
      "id": "8e97aaab-d2d0-4bb0-861d-e7f8e3eefdc6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ab7801a-7e80-49f2-9b07-b7c6c1686354"
      },
      "source": [
        "As you can see, the state contains 288x512x3 values. Therefor, we will use conv layers to deal with these values."
      ],
      "id": "8ab7801a-7e80-49f2-9b07-b7c6c1686354"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "b821acaa-62b8-4e69-872b-c92da14f4969",
        "outputId": "14388710-8283-4cf3-a657-304b710d3943"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f342232c910>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.imshow(state)"
      ],
      "id": "b821acaa-62b8-4e69-872b-c92da14f4969"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83212e65-b255-4942-aefc-350b06dfd83a"
      },
      "source": [
        "Here is the pic of the RGB state's representation"
      ],
      "id": "83212e65-b255-4942-aefc-350b06dfd83a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "82a55d9e-07c0-43d6-a7a1-ce076fef433c",
        "outputId": "1347001e-e3b4-472e-c595-4c15e6c5710c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3421dbfc90>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "state_converted = cv2.cvtColor(cv2.resize(state, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
        "plt.figure()\n",
        "plt.imshow(state_converted, cmap='gray')"
      ],
      "id": "82a55d9e-07c0-43d6-a7a1-ce076fef433c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef911b04-1b0d-4cd3-9aaf-69bf20033034"
      },
      "source": [
        "Here is the pic of the gray state's representation redimentioned with 80x80 ."
      ],
      "id": "ef911b04-1b0d-4cd3-9aaf-69bf20033034"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "071ffba5-3253-416b-99f3-2a01617683cb",
        "outputId": "d131d02c-8f4b-425c-fc8a-829a0e9afadd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3422294210>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "state_converted = cv2.adaptiveThreshold(state_converted,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
        "            cv2.THRESH_BINARY,11,2)\n",
        "plt.figure()\n",
        "plt.imshow(state_converted, cmap='gray')"
      ],
      "id": "071ffba5-3253-416b-99f3-2a01617683cb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eb378d8-fe8c-4b84-a6f9-9ff904a512bd"
      },
      "outputs": [],
      "source": [
        "def test(q_network) :\n",
        "    \n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    cum_sum = 0\n",
        "    while not done :\n",
        "        state_t = torch.as_tensor(state , dtype = torch.float32,device = device).unsqueeze(0)\n",
        "        action = torch.argmax(q_network(state_t)).item()\n",
        "        new_state,reward,done,_ = env.step(action)\n",
        "        state = new_state\n",
        "        cum_sum += reward\n",
        "        \n",
        "    return cum_sum"
      ],
      "id": "2eb378d8-fe8c-4b84-a6f9-9ff904a512bd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "569e2870-f1b6-4eeb-8179-d5a690f08e60"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Dueling Deep Q Network\n",
        "\"\"\"\n",
        "\n",
        "class DuelingQNetwork(nn.Module) :\n",
        "    \"\"\"\n",
        "    Implementation de la classe Dueling DQN\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "        nb_actions : int\n",
        "    ) : \n",
        "        \n",
        "        super().__init__()\n",
        "        self.nb_actions = nb_actions \n",
        "\n",
        "        # Linear -> ReLU -> Linear -> ReLU -> Linear\n",
        "        self.net =  nn.Sequential(\n",
        "            nn.Conv2d(4,32,8,stride = 4,padding=(0,0)),\n",
        "            nn.MaxPool2d(kernel_size=2 , padding=(0,0)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32,64,4,stride = 2 , padding = (1,1)),\n",
        "            nn.Dropout2d(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride = 2,padding = (1,1)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64,64,3,stride = 1, padding = (1,1)),\n",
        "            nn.Dropout2d(),\n",
        "            nn.MaxPool2d(kernel_size=2, padding = (1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 256),\n",
        "        )\n",
        "\n",
        "        # implementation pour la fonction avantage \n",
        "        # correspond a la sortie avantage du réseau de neurones\n",
        "        self.net_advantage = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, self.nb_actions)\n",
        "        )\n",
        "\n",
        "        # implementation pour la value function  \n",
        "        # correspond a la sortie value function du réseau de neurones\n",
        "        self.net_state_value = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,1)\n",
        "        )\n",
        "        \n",
        "    def advantage(self,x) :\n",
        "        return self.net_advantage(self.net(x))\n",
        "    \n",
        "    def state_value(self,x) :\n",
        "        return self.net_state_value(self.net(x))\n",
        "    \n",
        "    def forward(self,x) :\n",
        "        return self.state_value(x) + self.advantage(x) - torch.mean(self.advantage(x),dim=1).unsqueeze(1)"
      ],
      "id": "569e2870-f1b6-4eeb-8179-d5a690f08e60"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c75838ec-a20e-4f65-97c7-a51ed7e1bbc2"
      },
      "outputs": [],
      "source": [
        "class TrainModel :\n",
        "    \"\"\"\n",
        "    Class for training our D3QN Model\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "        nb_episode : int,\n",
        "        discount_factor : float,\n",
        "        learning_rate : float,\n",
        "        test_frequency : int,\n",
        "        nb_tests_iteration : int,\n",
        "        epsilon_decay : float,\n",
        "        epsilon_min : float,\n",
        "        batch_size : int,\n",
        "        size_replay_buffer : int,\n",
        "        update_frequency : int,\n",
        "        tau : float,\n",
        "        device\n",
        "    ) :\n",
        "        \n",
        "        \"\"\"\n",
        "        HYPER PARAMETERS\n",
        "        \"\"\"\n",
        "        \n",
        "        self.nb_episode = nb_episode # nombre d'episode d'entrainement\n",
        "        self.discount_factor = discount_factor # facteur d'actualisation\n",
        "        self.learning_rate = learning_rate # taux d'apprentissage\n",
        "        self.test_frequency = test_frequency # periode de test\n",
        "        self.nb_tests_iteration = nb_tests_iteration # periode d'affichage des tests\n",
        "        self.epsilon_decay = epsilon_decay # entre [0,1] coeficient multiplicateur de epsilon\n",
        "        self.epsilon_min = epsilon_min # valeur min de epsilon, jusqua combien elle peut diminuer\n",
        "        self.epsilon = 1.0 \n",
        "        self.batch_size = batch_size # taille du sous ensemble du replay buffer\n",
        "        self.size_replay_buffer = size_replay_buffer # taille du replay buyffer\n",
        "        self.update_frequency = update_frequency # periode de mise a jour du target network\n",
        "        self.tau = tau # facteur de synchronisation\n",
        "        \n",
        "        self.writer = SummaryWriter(\"./logs/d3qn_flappy_bird_rgb_rewards\")\n",
        "        \n",
        "        \n",
        "        \"\"\"\n",
        "        QNETWORK, QTARGETNETWORK AND BESTMODEL\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "\n",
        "        self.q_network , self.q_target_network, self.best_model = self.initialisation_q_networks() # initialisation et copie du q_network\n",
        "        self.best_value = -1e10\n",
        "        \n",
        "        \"\"\"\n",
        "        TESTING\n",
        "        \"\"\"\n",
        "        self.list_mean_rewards = list() \n",
        "        self.list_std_rewards = list()\n",
        "        \n",
        "    def initialisation_q_networks(self) :\n",
        "        \"\"\"\n",
        "        return :\n",
        "            q_network : DuelingQNetwork\n",
        "            q_target_network : DuelingQNetwork\n",
        "            best_model : DuelingQNetwork\n",
        "        \"\"\"\n",
        "        # initialisation des réseaux de neurones\n",
        "\n",
        "        q_network = DuelingQNetwork(\n",
        "            nb_actions = nb_actions\n",
        "        ).to(self.device)\n",
        "        \n",
        "        q_target_network = DuelingQNetwork(\n",
        "            nb_actions = nb_actions\n",
        "        ).to(self.device)\n",
        "        \n",
        "        best_model = DuelingQNetwork(\n",
        "            nb_actions = nb_actions\n",
        "        ).to(self.device)\n",
        "        \n",
        "        \"\"\" q_network copy \"\"\"\n",
        "        q_target_network.load_state_dict(q_network.state_dict())\n",
        "        best_model.load_state_dict(q_network.state_dict())\n",
        "\n",
        "        # on utilise comme optimizer Adam (a tester avec d'autres) \n",
        "        self.optimizer = torch.optim.Adam(q_network.parameters(), lr=self.learning_rate) \n",
        "        \n",
        "        return q_network , q_target_network, best_model\n",
        "        \n",
        "        \n",
        "    def pre_processing(self,state,old_frame = None) : \n",
        "        \"\"\"\n",
        "            input : np.array : \n",
        "            return : torch.tensor : \n",
        "        \"\"\"\n",
        "        if old_frame is None : \n",
        "            state_converted = cv2.cvtColor(cv2.resize(state, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
        "            state_stacked = np.stack((state_converted, state_converted, state_converted, state_converted), axis=2)\n",
        "            state_t = torch.as_tensor(state_stacked , device = self.device, dtype = torch.float32).unsqueeze(0).transpose(3 , 1)\n",
        "        else :\n",
        "            new_state_converted = cv2.cvtColor(cv2.resize(state, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
        "            new_state_converted = new_state_converted.reshape(new_state_converted.shape[0],new_state_converted.shape[1],1 )\n",
        "            state_stacked = np.append(new_state_converted, old_frame[:, :, :3], axis = 2)\n",
        "            state_t = torch.as_tensor(state_stacked , device = self.device, dtype = torch.float32).unsqueeze(0).transpose(3 , 1)\n",
        "            \n",
        "        return state_stacked,state_t\n",
        "        \n",
        "        \n",
        "    def training(self) :\n",
        "        \n",
        "        start_time = time.time()\n",
        "        replay_buffer = deque(maxlen=self.size_replay_buffer) # on utilise une file \n",
        "        timestep = 0\n",
        "        \n",
        "        env = FlappyBirdEnvRGB()\n",
        "        \n",
        "        for episode in range(self.nb_episode) :\n",
        "            state = env.reset()\n",
        "            state,state_t = self.pre_processing(state)\n",
        "            done = False\n",
        "            cumul = 0 # reward total\n",
        "            \n",
        "            self.epsilon = max(self.epsilon * self.epsilon_decay,self.epsilon_min)\n",
        "    \n",
        "            while not done : \n",
        "                \n",
        "                # epsilon-greedy pour la selection de l'action \n",
        "                if random.random() > self.epsilon : \n",
        "                    action = torch.argmax(self.q_network(state_t)).item()\n",
        "                else :\n",
        "                    action = env.action_space.sample()\n",
        "            \n",
        "                new_state,reward,done,_ = env.step(action)\n",
        "\n",
        "                new_state_stacked,new_state_t = self.pre_processing(new_state,state)\n",
        "                \n",
        "                cumul += reward\n",
        "                \n",
        "                transition = (state_t,action,done,reward,new_state_t) # a ajouter dans le replay buffer\n",
        "                replay_buffer.append(transition)\n",
        "\n",
        "                if len(replay_buffer) >= self.batch_size and timestep % self.update_frequency == 0 :\n",
        "                    \n",
        "                    # selection du batch aleatoirement\n",
        "                    batch = random.sample(replay_buffer,self.batch_size)\n",
        "\n",
        "                    # transformation en tensor\n",
        "                    \n",
        "                    states = [exp[0] for exp in batch]\n",
        "                    actions = np.asarray([exp[1] for exp in batch],dtype=int)\n",
        "                    dones = np.asarray([exp[2] for exp in batch],dtype=int)\n",
        "                    rewards = np.asarray([exp[3] for exp in batch],dtype=np.float32)\n",
        "                    new_states = [exp[4] for exp in batch]\n",
        "                    \n",
        "                    states_t = torch.stack(states).squeeze(1)\n",
        "                    new_states_t = torch.stack(new_states).squeeze(1)\n",
        "\n",
        "                    # states_t = torch.as_tensor(states , dtype=torch.float32, device = self.device)\n",
        "                    dones_t = torch.as_tensor(dones , dtype = torch.int64, device = self.device).unsqueeze(1)\n",
        "                    # new_states_t = torch.as_tensor(new_states , dtype=torch.float32, device = self.device)\n",
        "                    actions_t = torch.as_tensor(actions , dtype = torch.int64, device = self.device).unsqueeze(1)\n",
        "                    rewards_t = torch.as_tensor(rewards , dtype=torch.float32, device = self.device).unsqueeze(1)\n",
        "\n",
        "                    # l'esperance des futurs rewards\n",
        "                    y_target = (rewards_t + \n",
        "                                self.discount_factor * \n",
        "                                (1 - dones_t) * \n",
        "                                torch.gather(self.q_target_network(new_states_t),dim=1,index=torch.argmax(self.q_network(new_states_t),dim=1).unsqueeze(1)).detach())\n",
        "\n",
        "                    # descente de gradient \n",
        "                    mse = nn.MSELoss()\n",
        "                    loss = mse(torch.gather(self.q_network(states_t),dim=1,index=actions_t), y_target)\n",
        "                    self.optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "                    self.update_q_target_network()\n",
        "\n",
        "                timestep += 1\n",
        "                state = new_state_stacked\n",
        "                state_t = new_state_t\n",
        "            \n",
        "            # Partie Test\n",
        "            if episode % self.test_frequency == 0 :\n",
        "                \n",
        "                mean_rewards, std_rewards = self.testing()\n",
        "                \n",
        "                self.list_mean_rewards.append( mean_rewards )\n",
        "                self.list_std_rewards.append( std_rewards )\n",
        "                \n",
        "                end_time = time.time()\n",
        "                diff_time = end_time - start_time\n",
        "                start_time = time.time()\n",
        "                \"\"\"\n",
        "                Keep the best model\n",
        "                \"\"\"\n",
        "                if mean_rewards > self.best_value :\n",
        "                    self.best_value = mean_rewards\n",
        "                    self.best_model.load_state_dict(self.q_network.state_dict())\n",
        "                \n",
        "                \"\"\"\n",
        "                display :\n",
        "                \"\"\"\n",
        "                self.writer.add_scalar('TP3 : rewards FlappyBird', mean_rewards, episode)\n",
        "                print(f\"({(episode/self.nb_episode*100)}%) - Episode : {episode} - mean rewards : {mean_rewards} - std rewards : {std_rewards} - eps : {self.epsilon} - time : {diff_time}s - best value : {self.best_value}\")\n",
        "        \n",
        "        \n",
        "    def update_q_target_network(self) : \n",
        "        \"\"\" update du q-target en fonction du tau\"\"\"   \n",
        "        for target_param, local_param in zip(self.q_target_network.parameters(), self.q_network.parameters()):\n",
        "            target_param.data.copy_(self.tau*local_param.data + (1.0-self.tau)*target_param.data)  \n",
        "        \n",
        "        \n",
        "    def testing(self) :\n",
        "        \"\"\"\n",
        "            return :\n",
        "                list_cum_sum.mean : float\n",
        "                list_cum_sum.std : float\n",
        "        \"\"\"\n",
        "        list_cum_sum = list()\n",
        "        for i in range(self.nb_tests_iteration) :\n",
        "            list_cum_sum.append(self.one_test_model())\n",
        "            \n",
        "        list_cum_sum = np.asarray(list_cum_sum , dtype=np.float32)    \n",
        "        \n",
        "        return list_cum_sum.mean(), list_cum_sum.std()\n",
        "    \n",
        "            \n",
        "    def one_test_model(self) :\n",
        "        \"\"\"\n",
        "            return :\n",
        "                cum_sum : float (reward of an episode with the current q_network)\n",
        "        \"\"\"\n",
        "        random.seed(10)\n",
        "        \n",
        "        env = FlappyBirdEnvRGB()\n",
        "        \n",
        "        state = env.reset()\n",
        "        state,state_t = self.pre_processing(state)\n",
        "        done = False\n",
        "        cum_sum = 0.0\n",
        "        while not done :\n",
        "            action = torch.argmax(self.q_network(state_t)).item()\n",
        "            new_state,reward,done,_ = env.step(action)\n",
        "            new_state_stacked,new_state_t = self.pre_processing(new_state,state)\n",
        "            \n",
        "            state = new_state_stacked\n",
        "            state_t = new_state_t\n",
        "            cum_sum += reward\n",
        "                \n",
        "        return cum_sum\n",
        "    \n",
        "    def save_best_model(self) :\n",
        "        path = \"best_model_d3qn_lunarlanderdiscret\" + str(self.best_value)\n",
        "        torch.save(self.best_model.state_dict(),path)"
      ],
      "id": "c75838ec-a20e-4f65-97c7-a51ed7e1bbc2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a5544ba-fdda-48b5-b171-e6554301c063"
      },
      "source": [
        "## Hyper-parameters"
      ],
      "id": "0a5544ba-fdda-48b5-b171-e6554301c063"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f641342-7a1d-4575-be9b-f644b75a890e",
        "outputId": "1a659461-0acf-45c5-b0af-c45702b981be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device used cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cpu\") # torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device used {device}\")\n",
        "nb_episode = 10000000\n",
        "discount_factor = 0.99\n",
        "learning_rate = 0.0003\n",
        "test_frequency = 10\n",
        "nb_tests_iteration = 10\n",
        "epsilon_decay = 0.995\n",
        "epsilon_min = 0.01\n",
        "epsilon = 1.0\n",
        "batch_size = 64\n",
        "size_replay_buffer = 50000\n",
        "update_frequency = 1\n",
        "tau = 1e-3"
      ],
      "id": "7f641342-7a1d-4575-be9b-f644b75a890e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41a7478b-44e7-4e57-9fd8-bde50912fb5a"
      },
      "source": [
        "## Initialisation"
      ],
      "id": "41a7478b-44e7-4e57-9fd8-bde50912fb5a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f850ce3-3fe0-4863-aa22-ffada6b981b5"
      },
      "outputs": [],
      "source": [
        "nb_actions = 2\n",
        "\n",
        "train_model = TrainModel(\n",
        "      nb_episode = nb_episode,\n",
        "      discount_factor = discount_factor,\n",
        "      learning_rate = learning_rate,\n",
        "      test_frequency = test_frequency,\n",
        "      nb_tests_iteration = nb_tests_iteration,\n",
        "      epsilon_decay = epsilon_decay,\n",
        "      epsilon_min = epsilon_min,\n",
        "      batch_size = int(batch_size),\n",
        "      size_replay_buffer = size_replay_buffer,\n",
        "      update_frequency = update_frequency,\n",
        "      tau = tau,\n",
        "      device = device\n",
        ")"
      ],
      "id": "4f850ce3-3fe0-4863-aa22-ffada6b981b5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ed2d73-489c-4d49-8948-38091e918cde",
        "outputId": "17bcaaf9-be96-4a09-da33-b6a41b9c1118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.0%) - Episode : 0 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.995 - time : 11.373182773590088s - best value : 101.0\n",
            "(9.999999999999999e-05%) - Episode : 10 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.946354579813443 - time : 190.39256405830383s - best value : 101.0\n",
            "(0.00019999999999999998%) - Episode : 20 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.9000874278732445 - time : 189.4466164112091s - best value : 101.0\n",
            "(0.00030000000000000003%) - Episode : 30 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.8560822709551227 - time : 189.17620968818665s - best value : 101.0\n",
            "(0.00039999999999999996%) - Episode : 40 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.8142285204175609 - time : 189.51159286499023s - best value : 101.0\n",
            "(0.0005%) - Episode : 50 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.7744209942832988 - time : 196.52842450141907s - best value : 101.0\n",
            "(0.0006000000000000001%) - Episode : 60 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.736559652908221 - time : 189.2772557735443s - best value : 101.0\n",
            "(0.0007%) - Episode : 70 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.7005493475733617 - time : 189.9049105644226s - best value : 101.0\n",
            "(0.0007999999999999999%) - Episode : 80 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.6662995813682115 - time : 187.781809091568s - best value : 101.0\n",
            "(0.0009%) - Episode : 90 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.6337242817644086 - time : 189.68654704093933s - best value : 101.0\n",
            "(0.001%) - Episode : 100 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.6027415843082742 - time : 187.5110218524933s - best value : 101.0\n",
            "(0.0011%) - Episode : 110 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.5732736268885887 - time : 188.70281076431274s - best value : 101.0\n",
            "(0.0012000000000000001%) - Episode : 120 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.5452463540625918 - time : 187.8171877861023s - best value : 101.0\n",
            "(0.0013%) - Episode : 130 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.5185893309484582 - time : 187.99525570869446s - best value : 101.0\n",
            "(0.0014%) - Episode : 140 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.4932355662165453 - time : 187.91548538208008s - best value : 101.0\n",
            "(0.0015%) - Episode : 150 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.46912134373457726 - time : 190.1013126373291s - best value : 101.0\n",
            "(0.0015999999999999999%) - Episode : 160 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.446186062443672 - time : 189.49446272850037s - best value : 101.0\n",
            "(0.0017%) - Episode : 170 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.42437208406280985 - time : 186.81832027435303s - best value : 101.0\n",
            "(0.0018%) - Episode : 180 - mean rewards : 32.0 - std rewards : 0.0 - eps : 0.4036245882390106 - time : 183.66482591629028s - best value : 101.0\n",
            "(0.0019000000000000002%) - Episode : 190 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.38389143477919885 - time : 188.8117744922638s - best value : 101.0\n",
            "(0.002%) - Episode : 200 - mean rewards : 60.900001525878906 - std rewards : 24.043500900268555 - eps : 0.36512303261753626 - time : 184.8393816947937s - best value : 101.0\n",
            "(0.0021%) - Episode : 210 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.3472722151889232 - time : 187.5240137577057s - best value : 101.0\n",
            "(0.0022%) - Episode : 220 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.3302941218954743 - time : 186.4694893360138s - best value : 101.0\n",
            "(0.0023%) - Episode : 230 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.3141460853680822 - time : 186.76362586021423s - best value : 101.0\n",
            "(0.0024000000000000002%) - Episode : 240 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.2987875242397482 - time : 186.58040475845337s - best value : 101.0\n",
            "(0.0025%) - Episode : 250 - mean rewards : 102.30000305175781 - std rewards : 2.6851444244384766 - eps : 0.28417984116121187 - time : 187.17111802101135s - best value : 102.30000305175781\n",
            "(0.0026%) - Episode : 260 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.2702863258025825 - time : 185.88067412376404s - best value : 102.30000305175781\n",
            "(0.0026999999999999997%) - Episode : 270 - mean rewards : 33.900001525878906 - std rewards : 5.700000286102295 - eps : 0.2570720625972084 - time : 183.29823184013367s - best value : 102.30000305175781\n",
            "(0.0028%) - Episode : 280 - mean rewards : 38.900001525878906 - std rewards : 20.69999885559082 - eps : 0.24450384299593592 - time : 183.0995442867279s - best value : 102.30000305175781\n",
            "(0.0029%) - Episode : 290 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.23255008201124722 - time : 185.05667853355408s - best value : 102.30000305175781\n",
            "(0.003%) - Episode : 300 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.2211807388415433 - time : 186.46160292625427s - best value : 102.30000305175781\n",
            "(0.0031000000000000003%) - Episode : 310 - mean rewards : 51.20000076293945 - std rewards : 26.09137725830078 - eps : 0.21036724137609603 - time : 182.55608820915222s - best value : 102.30000305175781\n",
            "(0.0031999999999999997%) - Episode : 320 - mean rewards : 37.79999923706055 - std rewards : 8.885944366455078 - eps : 0.2000824143909432 - time : 182.9148027896881s - best value : 102.30000305175781\n",
            "(0.0033000000000000004%) - Episode : 330 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.1903004112552766 - time : 185.40043950080872s - best value : 102.30000305175781\n",
            "(0.0034%) - Episode : 340 - mean rewards : 32.0 - std rewards : 0.0 - eps : 0.18099664897669618 - time : 182.77841448783875s - best value : 102.30000305175781\n",
            "(0.0034999999999999996%) - Episode : 350 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.17214774642209296 - time : 185.32796835899353s - best value : 102.30000305175781\n",
            "(0.0036%) - Episode : 360 - mean rewards : 45.400001525878906 - std rewards : 20.406862258911133 - eps : 0.16373146555890544 - time : 183.62590837478638s - best value : 102.30000305175781\n",
            "(0.0036999999999999997%) - Episode : 370 - mean rewards : 80.30000305175781 - std rewards : 31.619773864746094 - eps : 0.1557266555690826 - time : 183.06145477294922s - best value : 102.30000305175781\n",
            "(0.0038000000000000004%) - Episode : 380 - mean rewards : 101.69999694824219 - std rewards : 2.0999999046325684 - eps : 0.14811319969530845 - time : 183.9377691745758s - best value : 102.30000305175781\n",
            "(0.0039%) - Episode : 390 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.14087196468590776 - time : 183.58922171592712s - best value : 102.30000305175781\n",
            "(0.004%) - Episode : 400 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.13398475271138335 - time : 184.8814606666565s - best value : 102.30000305175781\n",
            "(0.0041%) - Episode : 410 - mean rewards : 32.0 - std rewards : 0.0 - eps : 0.12743425563174798 - time : 182.24563550949097s - best value : 102.30000305175781\n",
            "(0.0042%) - Episode : 420 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.12120401149972035 - time : 183.00674104690552s - best value : 102.30000305175781\n",
            "(0.0043%) - Episode : 430 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.11527836319047392 - time : 183.4509198665619s - best value : 102.30000305175781\n",
            "(0.0044%) - Episode : 440 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.10964241905397228 - time : 184.86591291427612s - best value : 102.30000305175781\n",
            "(0.0045000000000000005%) - Episode : 450 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.1042820154910064 - time : 183.30594325065613s - best value : 102.30000305175781\n",
            "(0.0046%) - Episode : 460 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.09918368135888474 - time : 182.82947540283203s - best value : 102.30000305175781\n",
            "(0.004699999999999999%) - Episode : 470 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.0943346041173244 - time : 182.04575514793396s - best value : 102.30000305175781\n",
            "(0.0048000000000000004%) - Episode : 480 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.08972259762946533 - time : 183.21804928779602s - best value : 102.30000305175781\n",
            "(0.0049%) - Episode : 490 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.08533607153708872 - time : 183.0915162563324s - best value : 102.30000305175781\n",
            "(0.005%) - Episode : 500 - mean rewards : 102.9000015258789 - std rewards : 2.9816102981567383 - eps : 0.0811640021330769 - time : 182.96433901786804s - best value : 102.9000015258789\n",
            "(0.0051%) - Episode : 510 - mean rewards : 56.900001525878906 - std rewards : 25.970945358276367 - eps : 0.07719590465791494 - time : 181.775484085083s - best value : 102.9000015258789\n",
            "(0.0052%) - Episode : 520 - mean rewards : 32.0 - std rewards : 0.0 - eps : 0.07342180695061275 - time : 180.6552438735962s - best value : 102.9000015258789\n",
            "(0.0053%) - Episode : 530 - mean rewards : 32.0 - std rewards : 0.0 - eps : 0.06983222438783 - time : 180.2750322818756s - best value : 102.9000015258789\n",
            "(0.005399999999999999%) - Episode : 540 - mean rewards : 32.0 - std rewards : 0.0 - eps : 0.06641813604822402 - time : 180.0826096534729s - best value : 102.9000015258789\n",
            "(0.0055000000000000005%) - Episode : 550 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.06317096204211972 - time : 183.01845026016235s - best value : 102.9000015258789\n",
            "(0.0056%) - Episode : 560 - mean rewards : 35.79999923706055 - std rewards : 7.599999904632568 - eps : 0.06008254194952879 - time : 180.6097104549408s - best value : 102.9000015258789\n",
            "(0.0057%) - Episode : 570 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.05714511431233153 - time : 181.86912441253662s - best value : 102.9000015258789\n",
            "(0.0058%) - Episode : 580 - mean rewards : 101.0 - std rewards : 0.0 - eps : 0.0543512971290831 - time : 181.54637217521667s - best value : 102.9000015258789\n"
          ]
        }
      ],
      "source": [
        "train_model.training()"
      ],
      "id": "03ed2d73-489c-4d49-8948-38091e918cde"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53f72664-3fa7-46df-b8fe-99c6303c0043"
      },
      "outputs": [],
      "source": [
        "train_model.save_best_model()"
      ],
      "id": "53f72664-3fa7-46df-b8fe-99c6303c0043"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}